{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_folder = \"../input_annotations\"\n",
    "in_filename_csv = \"test_log.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\"caseid\", \"task\", \"end_timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseid_output = pd.read_csv(caseid_output_route, usecols=col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ", usecols=col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(input_data_folder, in_filename_csv), sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(input_data_folder, in_filename_csv), sep=\",\", usecols=col_list, dtype={'user': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_events_data(data):\n",
    "    \"\"\"\n",
    "    reads and parse all the events information from a csv file\n",
    "    \"\"\"\n",
    "    log = pd.read_csv(input, dtype={'user': str})\n",
    "    if one_timestamp:\n",
    "        column_names['Complete Timestamp'] = 'end_timestamp'\n",
    "        log = log.rename(columns=column_names)\n",
    "        log = log.astype({'caseid': object})\n",
    "        log = (log[(log.task != 'Start') & (log.task != 'End')]\n",
    "               .reset_index(drop=True))\n",
    "        if filter_d_attrib:\n",
    "            log = log[['caseid', 'task', 'user', 'end_timestamp']]\n",
    "        log['end_timestamp'] = pd.to_datetime(log['end_timestamp'],\n",
    "                                              format=timeformat)\n",
    "    else:\n",
    "        column_names['Start Timestamp'] = 'start_timestamp'\n",
    "        column_names['Complete Timestamp'] = 'end_timestamp'\n",
    "        log = log.rename(columns=column_names)\n",
    "        log = log.astype({'caseid': object})\n",
    "        log = (log[(log.task != 'Start') & (log.task != 'End')]\n",
    "               .reset_index(drop=True))\n",
    "        if filter_d_attrib:\n",
    "            log = log[['caseid', 'task', 'user',\n",
    "                       'start_timestamp', 'end_timestamp']]\n",
    "        log['start_timestamp'] = pd.to_datetime(log['start_timestamp'],\n",
    "                                                format=timeformat)\n",
    "        log['end_timestamp'] = pd.to_datetime(log['end_timestamp'],\n",
    "                                              format=timeformat)\n",
    "    log['user'].fillna('SYS', inplace=True)\n",
    "    data = log.to_dict('records')\n",
    "    append_csv_start_end()\n",
    "    split_event_transitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_csv_start_end(data):\n",
    "    new_data = list()\n",
    "    data = sorted(data, key=lambda x: x['caseid'])\n",
    "    for key, group in it.groupby(data, key=lambda x: x['caseid']):\n",
    "        trace = list(group)\n",
    "        for new_event in ['Start', 'End']:\n",
    "            idx = 0 if new_event == 'Start' else -1\n",
    "            t_key = 'end_timestamp'\n",
    "            if not one_timestamp and new_event == 'Start':\n",
    "                t_key = 'start_timestamp'\n",
    "            temp_event = dict()\n",
    "            temp_event['caseid'] = trace[idx]['caseid']\n",
    "            temp_event['task'] = new_event\n",
    "            temp_event['user'] = new_event\n",
    "            temp_event['end_timestamp'] = trace[idx][t_key]\n",
    "            if not one_timestamp:\n",
    "                temp_event['start_timestamp'] = trace[idx][t_key]\n",
    "            if new_event == 'Start':\n",
    "                trace.insert(0, temp_event)\n",
    "            else:\n",
    "                trace.append(temp_event)\n",
    "        new_data.extend(trace)\n",
    "    data = new_data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_event_transitions(data, one_timestamp ):\n",
    "    temp_raw = list()\n",
    "    if one_timestamp:\n",
    "        for event in data:\n",
    "            temp_event = event.copy()\n",
    "            temp_event['timestamp'] = temp_event.pop('end_timestamp')\n",
    "            temp_event['event_type'] = 'complete'\n",
    "            temp_raw.append(temp_event)\n",
    "    else:\n",
    "        for event in data:\n",
    "            start_event = event.copy()\n",
    "            complete_event = event.copy()\n",
    "            start_event.pop('end_timestamp')\n",
    "            complete_event.pop('start_timestamp')\n",
    "            start_event['timestamp'] = start_event.pop('start_timestamp')\n",
    "            complete_event['timestamp'] = complete_event.pop('end_timestamp')\n",
    "            start_event['event_type'] = 'start'\n",
    "            complete_event['event_type'] = 'complete'\n",
    "            temp_raw.append(start_event)\n",
    "            temp_raw.append(complete_event)\n",
    "    data = temp_raw\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv(os.path.join(input_data_folder, in_filename_csv), sep=\",\", dtype={'user': str})\n",
    "one_timestamp = True\n",
    "timeformat = '%Y-%m-%dT%H:%M:%S.%f'\n",
    "column_names = {'Case ID': 'caseid',\n",
    "                'Activity': 'task',\n",
    "                'lifecycle:transition': 'event_type', #---#\n",
    "                'Resource': 'user'}\n",
    "filter_d_attrib = {\n",
    "    'timeformat': '%Y-%m-%dT%H:%M:%S.%f',\n",
    "    'column_names': column_names,\n",
    "    'one_timestamp': one_timestamp,\n",
    "    'ns_include': True}\n",
    "if one_timestamp:\n",
    "    column_names['Complete Timestamp'] = 'end_timestamp'\n",
    "    log = log.rename(columns=column_names)\n",
    "    log = log.astype({'caseid': object})\n",
    "    log = (log[(log.task != 'Start') & (log.task != 'End')]\n",
    "           .reset_index(drop=True))\n",
    "    if filter_d_attrib:\n",
    "        log = log[['caseid', 'task', 'user', 'end_timestamp']]\n",
    "    log['end_timestamp'] = pd.to_datetime(log['end_timestamp'],\n",
    "                                          format=timeformat)\n",
    "else:\n",
    "    column_names['Start Timestamp'] = 'start_timestamp'\n",
    "    column_names['Complete Timestamp'] = 'end_timestamp'\n",
    "    log = log.rename(columns=column_names)\n",
    "    log = log.astype({'caseid': object})\n",
    "    log = (log[(log.task != 'Start') & (log.task != 'End')]\n",
    "           .reset_index(drop=True))\n",
    "    if filter_d_attrib:\n",
    "        log = log[['caseid', 'task', 'user',\n",
    "                   'start_timestamp', 'end_timestamp']]\n",
    "    log['start_timestamp'] = pd.to_datetime(log['start_timestamp'],\n",
    "                                            format=timeformat)\n",
    "    log['end_timestamp'] = pd.to_datetime(log['end_timestamp'],\n",
    "                                          format=timeformat)\n",
    "log['user'].fillna('SYS', inplace=True)\n",
    "data = log.to_dict('records')\n",
    "data = append_csv_start_end(data)\n",
    "data = split_event_transitions(data, one_timestamp)\n",
    "data = pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(self.output_route,\n",
    "                    'parameters',\n",
    "                    'model_parameters.json')\n",
    "\n",
    "if 'activity' in data:\n",
    "    del data['activity']\n",
    "self.parms = {**self.parms, **{k: v for k, v in data.items()}}\n",
    "self.parms['dim'] = {k: int(v) for k, v in data['dim'].items()}\n",
    "with open(path) as file:\n",
    "    filter_parms_data = json.load(file)\n",
    "    filter_parms['index_ac'] = {int(k): v\n",
    "                              for k, v in data['index_ac'].items()}\n",
    "    filter_parms['index_rl'] = {int(k): v\n",
    "                              for k, v in data['index_rl'].items()}\n",
    "    file.close()\n",
    "    self.ac_index = {v: k for k, v in self.parms['index_ac'].items()}\n",
    "    self.rl_index = {v: k for k, v in self.parms['index_rl'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [[1,2,3,4],[5,6,7,8,9,10],[11,12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = l.index([5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictA = {1:'Y', 2:'E', 3:'E'}\n",
    "dictB = {\"A\":'Y', \"B\":'A', \"C\":'W'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictB[\"A\"] in dictA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, age in dictA.items():\n",
    "    if age == dictB[\"A\"]:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [[0], [0, 4.0], [0, 4.0, 6.0], [0, 4.0, 6.0, 3.0], [0, 4.0, 6.0, 3.0, 10.0], [0, 4.0, 6.0, 3.0, 10.0, 5.0], [0, 4.0, 6.0, 3.0, 10.0, 5.0, 8.0], [0, 4.0, 6.0, 3.0, 10.0, 5.0, 8.0, 7.0], [0, 4.0, 6.0, 3.0, 10.0, 5.0, 8.0, 7.0, 12.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from streamlit.hashing import _CodeHasher\n",
    "\n",
    "try:\n",
    "    # Before Streamlit 0.65\n",
    "    from streamlit.ReportThread import get_report_ctx\n",
    "    from streamlit.server.Server import Server\n",
    "except ModuleNotFoundError:\n",
    "    # After Streamlit 0.65\n",
    "    from streamlit.report_thread import get_report_ctx\n",
    "    from streamlit.server.server import Server\n",
    "\n",
    "\n",
    "def main():\n",
    "    state = _get_state()\n",
    "    pages = {\n",
    "        \"Dashboard\": page_dashboard,\n",
    "        \"Settings\": page_settings,\n",
    "    }\n",
    "\n",
    "    st.sidebar.title(\":floppy_disk: Page states\")\n",
    "    page = st.sidebar.radio(\"Select your page\", tuple(pages.keys()))\n",
    "\n",
    "    # Display the selected page with the session state\n",
    "    pages[page](state)\n",
    "\n",
    "    # Mandatory to avoid rollbacks with widgets, must be called at the end of your app\n",
    "    state.sync()\n",
    "\n",
    "\n",
    "def page_dashboard(state):\n",
    "    st.title(\":chart_with_upwards_trend: Dashboard page\")\n",
    "    display_state_values(state)\n",
    "\n",
    "\n",
    "def page_settings(state):\n",
    "    st.title(\":wrench: Settings\")\n",
    "    display_state_values(state)\n",
    "\n",
    "    st.write(\"---\")\n",
    "    options = [\"Hello\", \"World\", \"Goodbye\"]\n",
    "    state.input = st.text_input(\"Set input value.\", state.input or \"\")\n",
    "    state.slider = st.slider(\"Set slider value.\", 1, 10, state.slider)\n",
    "    state.radio = st.radio(\"Set radio value.\", options, options.index(state.radio) if state.radio else 0)\n",
    "    state.checkbox = st.checkbox(\"Set checkbox value.\", state.checkbox)\n",
    "    state.selectbox = st.selectbox(\"Select value.\", options, options.index(state.selectbox) if state.selectbox else 0)\n",
    "    state.multiselect = st.multiselect(\"Select value(s).\", options, state.multiselect)\n",
    "\n",
    "    # Dynamic state assignments\n",
    "    for i in range(3):\n",
    "        key = f\"State value {i}\"\n",
    "        state[key] = st.slider(f\"Set value {i}\", 1, 10, state[key])\n",
    "\n",
    "\n",
    "def display_state_values(state):\n",
    "    st.write(\"Input state:\", state.input)\n",
    "    st.write(\"Slider state:\", state.slider)\n",
    "    st.write(\"Radio state:\", state.radio)\n",
    "    st.write(\"Checkbox state:\", state.checkbox)\n",
    "    st.write(\"Selectbox state:\", state.selectbox)\n",
    "    st.write(\"Multiselect state:\", state.multiselect)\n",
    "    \n",
    "    for i in range(3):\n",
    "        st.write(f\"Value {i}:\", state[f\"State value {i}\"])\n",
    "\n",
    "    if st.button(\"Clear state\"):\n",
    "        state.clear()\n",
    "\n",
    "\n",
    "class _SessionState:\n",
    "\n",
    "    def __init__(self, session, hash_funcs):\n",
    "        \"\"\"Initialize SessionState instance.\"\"\"\n",
    "        self.__dict__[\"_state\"] = {\n",
    "            \"data\": {},\n",
    "            \"hash\": None,\n",
    "            \"hasher\": _CodeHasher(hash_funcs),\n",
    "            \"is_rerun\": False,\n",
    "            \"session\": session,\n",
    "        }\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        \"\"\"Initialize state data once.\"\"\"\n",
    "        for item, value in kwargs.items():\n",
    "            if item not in self._state[\"data\"]:\n",
    "                self._state[\"data\"][item] = value\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"Return a saved state value, None if item is undefined.\"\"\"\n",
    "        return self._state[\"data\"].get(item, None)\n",
    "        \n",
    "    def __getattr__(self, item):\n",
    "        \"\"\"Return a saved state value, None if item is undefined.\"\"\"\n",
    "        return self._state[\"data\"].get(item, None)\n",
    "\n",
    "    def __setitem__(self, item, value):\n",
    "        \"\"\"Set state value.\"\"\"\n",
    "        self._state[\"data\"][item] = value\n",
    "\n",
    "    def __setattr__(self, item, value):\n",
    "        \"\"\"Set state value.\"\"\"\n",
    "        self._state[\"data\"][item] = value\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Clear session state and request a rerun.\"\"\"\n",
    "        self._state[\"data\"].clear()\n",
    "        self._state[\"session\"].request_rerun()\n",
    "    \n",
    "    def sync(self):\n",
    "        \"\"\"Rerun the app with all state values up to date from the beginning to fix rollbacks.\"\"\"\n",
    "\n",
    "        # Ensure to rerun only once to avoid infinite loops\n",
    "        # caused by a constantly changing state value at each run.\n",
    "        #\n",
    "        # Example: state.value += 1\n",
    "        if self._state[\"is_rerun\"]:\n",
    "            self._state[\"is_rerun\"] = False\n",
    "        \n",
    "        elif self._state[\"hash\"] is not None:\n",
    "            if self._state[\"hash\"] != self._state[\"hasher\"].to_bytes(self._state[\"data\"], None):\n",
    "                self._state[\"is_rerun\"] = True\n",
    "                self._state[\"session\"].request_rerun()\n",
    "\n",
    "        self._state[\"hash\"] = self._state[\"hasher\"].to_bytes(self._state[\"data\"], None)\n",
    "\n",
    "\n",
    "def _get_session():\n",
    "    session_id = get_report_ctx().session_id\n",
    "    session_info = Server.get_current()._get_session_info(session_id)\n",
    "\n",
    "    if session_info is None:\n",
    "        raise RuntimeError(\"Couldn't get your Streamlit Session object.\")\n",
    "    \n",
    "    return session_info.session\n",
    "\n",
    "\n",
    "def _get_state(hash_funcs=None):\n",
    "    session = _get_session()\n",
    "\n",
    "    if not hasattr(session, \"_custom_session_state\"):\n",
    "        session._custom_session_state = _SessionState(session, hash_funcs)\n",
    "\n",
    "    return session._custom_session_state\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [u-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms['multiprednum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words as nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw(1, lang=\"en\", to=\"ordinal_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state = {'pos_tm_ss': [[0], [0.0002507188]], \n",
    "'initial_prediction': {'ss_initpredict1': {'pos_ac_ss': [], 'pos_rl_ss': [0, 2], 'pos_lb_ss': [0, 1]}, \n",
    "\t\t\t\t\t\t'ss_initpredict2': {'pos_ac_ss': [0, 10], 'pos_rl_ss': [0, 4], 'pos_lb_ss': [0, 0]}, \n",
    "\t\t\t\t\t\t'ss_initpredict3': {'pos_ac_ss': [0, 3], 'pos_rl_ss': [0, 5], 'pos_lb_ss': [0, 0]}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hist_columns = ['pos_ac_ss', 'pos_rl_ss', 'pos_lb_ss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lk in range(3):\n",
    "    _hist_predicted_dict_arl = dict([(k, session_state['initial_prediction']['ss_initpredict'+str(lk+1)][k]) for k in _hist_columns ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hist_predicted_dict_arl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hist_predicted_dict_arl.update(dict([(k, session_state[k]) for k in ['pos_tm_ss']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hist_predicted_dict_arl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session_state['initial_prediction']['ss_initpredict1']['pos_ac_ss'] != []:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ['SME', 'Prediction 1', 'Prediction 2', 'Prediction 3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kz in range(3+1):\n",
    "    x = z[kz]\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_ = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_['history_of_choice'] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_['history_of_choice'] = {'hist_ac_prefix': [], 'hist_rl_prefix': [], 'hist_lb_prefix': [], 'hist_tm_prefix': [], 'hist_pred_prefix': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zx = [np.array([0.00025072]), np.array([0.38379776])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state['multi_pred_ss'] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _zx in range(3):\n",
    "    session_state['multi_pred_ss'][\"ss_multipredict{0}\".format(_zx + 1)] = {}\n",
    "    for _ux in range(3):\n",
    "        session_state['multi_pred_ss'][\"ss_multipredict\" + str(_zx + 1)][\"multiverse_predict{0}\".format(_ux + 1)] = {'ac_pred': [], 'ac_prob': [], 'rl_pred': [], 'rl_prob': [], 'label_pred': [], 'label_prob': [], 'tm_pred': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_state['multi_pred_ss']['ss_multipredict1']['multiverse_predict1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[random.choice(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.extend([None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyla\n"
     ]
    }
   ],
   "source": [
    "x = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello  leyla\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
