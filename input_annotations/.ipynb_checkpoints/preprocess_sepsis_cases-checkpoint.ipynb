{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pm4py as pm\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.conversion.log import converter as log_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_folder = \"../orig_logs\"\n",
    "output_data_folder = \"../input_files\"\n",
    "in_filename_xes = \"sepsis_cases.xes\"\n",
    "in_filename_csv = \"sepsis_cases.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = xes_importer.Variants.LINE_BY_LINE\n",
    "parameters = {variant.value.Parameters.TIMESTAMP_SORT: True}\n",
    "log = xes_importer.apply(os.path.join(input_data_folder, in_filename_xes),\n",
    "                         variant=variant, parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = log_converter.apply(log, variant=log_converter.Variants.TO_DATA_FRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.rename(columns={'case:concept:name': 'Case ID', 'concept:name': 'Activity', \n",
    "                          'time:timestamp': 'Complete Timestamp', 'org:group' : 'user'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(os.path.join(input_data_folder, in_filename_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id_col = \"Case ID\"\n",
    "activity_col = \"Activity\"\n",
    "timestamp_col = \"Complete Timestamp\"\n",
    "label_col = \"label\"\n",
    "pos_label = \"deviant\"\n",
    "neg_label = \"regular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_freq_threshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_cat_cols = [\"Activity\", 'user'] # i.e. event attributes\n",
    "static_cat_cols = ['Diagnose', 'DiagnosticArtAstrup', 'DiagnosticBlood', 'DiagnosticECG',\n",
    "       'DiagnosticIC', 'DiagnosticLacticAcid', 'DiagnosticLiquor',\n",
    "       'DiagnosticOther', 'DiagnosticSputum', 'DiagnosticUrinaryCulture',\n",
    "       'DiagnosticUrinarySediment', 'DiagnosticXthorax', 'DisfuncOrg',\n",
    "       'Hypotensie', 'Hypoxie', 'InfectionSuspected', 'Infusion', 'Oligurie',\n",
    "       'SIRSCritHeartRate', 'SIRSCritLeucos', 'SIRSCritTachypnea',\n",
    "       'SIRSCritTemperature', 'SIRSCriteria2OrMore'] # i.e. case attributes that are known from the start\n",
    "dynamic_num_cols = ['CRP', 'LacticAcid', 'Leucocytes']\n",
    "static_num_cols = ['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_cols = static_cat_cols + static_num_cols + [case_id_col]\n",
    "dynamic_cols = dynamic_cat_cols + dynamic_num_cols + [timestamp_col]\n",
    "cat_cols = dynamic_cat_cols + static_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timestamp_features(group):\n",
    "    \n",
    "    group = group.sort_values(timestamp_col, ascending=False, kind='mergesort')\n",
    "    \n",
    "    tmp = group[timestamp_col] - group[timestamp_col].shift(-1)\n",
    "    #tmp = tmp.fillna(0)\n",
    "    #group[\"timesincelastevent\"] = tmp.apply(lambda x: float(x / np.timedelta64(1, 'm'))) # m is for minutes\n",
    "    group[\"timesincelastevent\"] = tmp.apply(lambda x: float(x / pd.Timedelta(1, 'm'))) # m is for minutes\n",
    "\n",
    "    tmp = group[timestamp_col] - group[timestamp_col].iloc[-1]\n",
    "    #tmp = tmp.fillna(0)\n",
    "    #group[\"timesincecasestart\"] = tmp.apply(lambda x: float(x / np.timedelta64(1, 'm'))) # m is for minutes\n",
    "    group[\"timesincecasestart\"] = tmp.apply(lambda x: float(x / pd.Timedelta(1, 'm'))) # m is for minutes\n",
    "\n",
    "    group = group.sort_values(timestamp_col, ascending=True, kind='mergesort')\n",
    "    group[\"event_nr\"] = range(1, len(group) + 1)\n",
    "    \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_before_activity(group):\n",
    "    relevant_activity_idxs = np.where(group[activity_col] == relevant_activity)[0]\n",
    "    if len(relevant_activity_idxs) > 0:\n",
    "        cut_idx = relevant_activity_idxs[0]\n",
    "        return group[:cut_idx]\n",
    "    else:\n",
    "        return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_open_cases(date):\n",
    "    return sum((dt_first_last_timestamps[\"start_time\"] <= date) & (dt_first_last_timestamps[\"end_time\"] > date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_activity_exists(group, activity):\n",
    "    relevant_activity_idxs = np.where(group[activity_col] == activity)[0]\n",
    "    if len(relevant_activity_idxs) > 0:\n",
    "        idx = relevant_activity_idxs[0]\n",
    "        group[label_col] = pos_label\n",
    "        return group[:idx]\n",
    "    else:\n",
    "        group[label_col] = neg_label\n",
    "        return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_activity_exists_and_time_less_than(group, activity):\n",
    "    relevant_activity_idxs = np.where(group[activity_col] == activity)[0]\n",
    "    if len(relevant_activity_idxs) > 0:\n",
    "        idx = relevant_activity_idxs[0]\n",
    "        if group[\"timesincelastevent\"].iloc[idx] <= 28 * 1440: # return in less than 28 days\n",
    "            group[label_col] = pos_label\n",
    "            return group[:idx]\n",
    "        else:\n",
    "            group[label_col] = neg_label\n",
    "            return group[:idx]\n",
    "    else:\n",
    "        group[label_col] = neg_label\n",
    "        return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_any_of_activities_exist(group, activities):\n",
    "    if np.sum(group[activity_col].isin(activities)) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(input_data_folder, in_filename_csv), sep=\",\")\n",
    "data.rename(columns={\"Unnamed: 0\" : \"event_nr\"}, inplace=True)\n",
    "data[case_id_col] = data[case_id_col].fillna(\"missing_caseid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove incomplete cases\n",
    "tmp = data.groupby(case_id_col).apply(check_if_any_of_activities_exist, activities=[\"Release A\", \"Release B\", \"Release C\", \"Release D\", \"Release E\"])\n",
    "incomplete_cases = tmp.index[tmp==False]\n",
    "data = data[~data[case_id_col].isin(incomplete_cases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = [static_cols + dynamic_cols]\n",
    "#data = data.reindex(columns=columns)\n",
    "data = data[static_cols + dynamic_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features extracted from timestamp\n",
    "data[timestamp_col] = pd.to_datetime(data[timestamp_col], utc=True)\n",
    "data[\"timesincemidnight\"] = data[timestamp_col].dt.hour * 60 + data[timestamp_col].dt.minute\n",
    "data[\"month\"] = data[timestamp_col].dt.month\n",
    "data[\"weekday\"] = data[timestamp_col].dt.weekday\n",
    "data[\"hour\"] = data[timestamp_col].dt.hour\n",
    "data = data.groupby(case_id_col).apply(extract_timestamp_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add inter-case features\n",
    "data = data.sort_values([timestamp_col], ascending=True, kind='mergesort')\n",
    "dt_first_last_timestamps = data.groupby(case_id_col)[timestamp_col].agg([min, max])\n",
    "dt_first_last_timestamps.columns = [\"start_time\", \"end_time\"]\n",
    "data[\"open_cases\"] = data[timestamp_col].apply(get_open_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values\n",
    "grouped = data.sort_values(timestamp_col, ascending=True, kind='mergesort').groupby(case_id_col)\n",
    "for col in static_cols + dynamic_cols:\n",
    "    data[col] = grouped[col].transform(lambda grp: grp.fillna(method='ffill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cat_cols] = data[cat_cols].fillna('missing')\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    counts = data[col].value_counts()\n",
    "    mask = data[col].isin(counts[counts >= category_freq_threshold].index)\n",
    "    data.loc[~mask, col] = \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first labeling\n",
    "dt_labeled = data.sort_values(timestamp_col, ascending=True, kind=\"mergesort\").groupby(case_id_col).apply(check_if_activity_exists_and_time_less_than, activity=\"Return ER\")\n",
    "dt_labeled.to_csv(os.path.join(output_data_folder, \"sepsis_cases_1.csv\"), sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second labeling\n",
    "dt_labeled = data.sort_values(timestamp_col, ascending=True, kind=\"mergesort\").groupby(case_id_col).apply(check_if_activity_exists, activity=\"Admission IC\")\n",
    "dt_labeled.to_csv(os.path.join(output_data_folder, \"sepsis_cases_2.csv\"), sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth labeling\n",
    "dt_labeled = data.sort_values(timestamp_col, ascending=True, kind=\"mergesort\").groupby(case_id_col).apply(check_if_activity_exists, activity=\"Release A\")\n",
    "dt_labeled.to_csv(os.path.join(output_data_folder, \"sepsis_cases_3.csv\"), sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
